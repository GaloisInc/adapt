package com.galois.adapt

import java.io._
import java.text.NumberFormat
import akka.actor.{ActorRef, Props}
import akka.http.scaladsl.Http
import akka.http.scaladsl.server.RouteResult._
import akka.pattern.ask
import akka.stream.{ActorMaterializer, _}
import akka.stream.scaladsl._
import akka.util.Timeout
import com.galois.adapt.adm._
import FlowComponents._
import akka.NotUsed
import akka.event.Logging
import shapeless._
import shapeless.syntax.singleton._
import AdaptConfig._
import com.typesafe.config.ConfigFactory
import com.galois.adapt.FilterCdm.Filter
import com.galois.adapt.MapSetUtils.{AlmostMap, AlmostSet}
import com.galois.adapt.NoveltyDetection.{Event => _, _}
import com.galois.adapt.cdm20._
import scala.collection.mutable
import scala.concurrent.duration._
import scala.concurrent.{Await, ExecutionContext, Future}
import scala.language.postfixOps
import scala.util.{Failure, Random, Success, Try}
import sys.process._
import com.rrwright.quine.runtime._
import com.rrwright.quine.language._
//import com.rrwright.quine.language.JavaObjectSerializationScheme._
import com.rrwright.quine.language.BoopickleScheme._


object Application extends App {
  org.slf4j.LoggerFactory.getILoggerFactory  // This is here just to make SLF4j shut up and not log lots of error messages when instantiating the Kafka producer.
  runFlow match { case "quine" => (); case _ => wrongRunFlow() }

  // Open up for SSH ammonite shelling via `ssh repl@localhost -p22222`
  import ammonite.sshd._
  import org.apache.sshd.server.auth.password.AcceptAllPasswordAuthenticator
  val replServer = new SshdRepl(
    SshServerConfig(
      address = "localhost", // or "0.0.0.0" for public-facing shells
      port = AdaptConfig.runtimeConfig.port + 10000, // Any available port
      passwordAuthenticator = Some(AcceptAllPasswordAuthenticator.INSTANCE)
    ),
    predef = "repl.frontEnd() = ammonite.repl.FrontEnd.JLineUnix"
  )
  replServer.start()

  // Some random string that uniquely identifies this run
  val randomIdentifier: String = {
    val length = 10
    val buffer = StringBuilder.newBuilder

    val chars = "ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789".toCharArray
    val random = new java.util.Random(System.currentTimeMillis())

    for (i <- 1 until length)
      buffer.append(chars(random.nextInt(chars.length)))

    buffer.toString()
  }

  // A summary of some interesting stats about this run
  val summary: Array[(String, String)] = {
    val hostname: Try[java.net.InetAddress] = Try(java.net.InetAddress.getLocalHost)  // Host name and IP
    val date: java.util.Date = java.util.Calendar.getInstance.getTime                 // Right now
    val cores: Int = Runtime.getRuntime.availableProcessors                           // # cores available to the JVM
    val freeGb: Double = Runtime.getRuntime.totalMemory().toDouble / 1e9              // GB available to the JVM
    val commit: Try[String] = Try("git rev-parse HEAD".!!)

    Array(
      "Identifier:" -> randomIdentifier,
      "Host name:"  -> hostname.toOption.fold("could not determine host name")(_.toString),
      "Date:"       -> date.toString,
      "Cores:"      -> cores.toString,
      "Mem (GB):"   -> freeGb.toString,
      "Git commit:" -> commit.getOrElse("could not determine git commit")
    )
  }


  println(s"Information identifying this run:\n${summary.map(x => s"  ${x._1} ${x._2}").mkString("\n")}")


  // Write stats about this run to config file passed in with `-Dconfig.file=...` if found
//  Option(System.getProperty("config.file")) match {
//    case None =>
//      println("Failed to find a config file to which to append information about this run.")
//    case Some(configFilePath) =>
//      val configFileWriter = new FileWriter(configFilePath, true)
//      configFileWriter.write("\n")
//      configFileWriter.write("// AUTOGENERATED (when this config was used)\n")
//      for ((k,v) <- summary) configFileWriter.write(s"//   $k $v\n")
//      configFileWriter.close()
//  }


  val hostConfigSrcs: List[String] = quineConfig.hosts
    .zipWithIndex
    .map { case (QuineHost(ip, shardCount, _), idx) =>
      s"""|  {
          |    hostname = $ip
          |    port = 2551
          |    first-shard = ${ quineConfig.hosts.take(idx).map(_.shardcount).sum }
          |    last-shard = ${  quineConfig.hosts.take(idx).map(_.shardcount).sum + shardCount - 1 }
          |  }
          |""".stripMargin
    }

  val clusterConfigSrc =
    s"""|name = "adapt-cluster"
        |hostname = "${quineConfig.thishost}"
        |port = 2551
        |host-shard-ranges = ${hostConfigSrcs.mkString("[\n",",","]\n")}
        |""".stripMargin

  implicit val graph = GraphService.clustered(
    config = ConfigFactory.parseString(clusterConfigSrc),
    persistor = as => LMDBSnapshotPersistor(
      mapSizeBytes = {
        val size: Long = runtimeConfig.lmdbgigabytes * 1024L * 1024L * 1024L
        println("LMDB size: " + NumberFormat.getInstance().format(size))
        size
      }
    )(as), // EmptyPersistor()(as),
    idProvider = AdmUuidProvider,
    indexer = Indexer.currentIndex(EmptyIndex),
    inMemorySoftNodeLimit = Some(quineConfig.inmemsoftlimit),
    inMemoryHardNodeLimit = Some(quineConfig.inmemhardlimit),
    uiPort = None
  )
  implicit val system = graph.system

  // Wait for all members of the cluster to be ready:
  val clusterStartupDeadline: Deadline = 300.seconds.fromNow
  while ( ! graph.clusterIsReady) {
    if (clusterStartupDeadline.isOverdue()) throw new RuntimeException(s"Timeout expired while waiting for cluster hosts to become active.")
    Thread.sleep(1000)
  }


  val ppmBaseDirFile = new File(ppmConfig.basedir)
  if ( ! ppmBaseDirFile.exists()) ppmBaseDirFile.mkdir()


  // All large maps should be store in `MapProxy`
  val hostNames: List[HostName] = ingestConfig.hosts.map(_.hostName)
  val hostNameForAllHosts = "BetweenHosts"

  val mapProxy: MapProxy = new MapProxy(
    fileDbPath = admConfig.mapdb,
    fileDbBypassChecksum = admConfig.mapdbbypasschecksum,
    fileDbTransactions = admConfig.mapdbtransactions,

    admConfig.uuidRemapperShards,
    hostNames,
    hostNameForAllHosts,
    cdm2cdmLruCacheSize = admConfig.cdm2cdmlrucachesize,
    cdm2admLruCacheSize = admConfig.cdm2admlrucachesize,
    dedupEdgeCacheSize = admConfig.dedupEdgeCacheSize
  )

  // These are the maps that `UUIDRemapper` will use
  val cdm2cdmMaps: Map[HostName, Array[AlmostMap[CdmUUID,CdmUUID]]] = mapProxy.cdm2cdmMapShardsMap
  val cdm2admMaps: Map[HostName, Array[AlmostMap[CdmUUID,AdmUUID]]] = mapProxy.cdm2admMapShardsMap

  // Edges blocked waiting for a target CDM uuid to be remapped.
  val blockedEdgesMaps: Map[HostName, Array[mutable.Map[CdmUUID, (List[Edge], Set[CdmUUID])]]] = mapProxy.blockedEdgesShardsMap

  val seenEdgesMaps: Map[HostName, Array[AlmostSet[EdgeAdm2Adm]]] = mapProxy.seenEdgesShardsMap
  val seenNodesMaps: Map[HostName, Array[AlmostSet[AdmUUID]]] = mapProxy.seenNodesShardsMap
  val uuidRemapperShardCounts: Map[HostName, Array[Long]] = hostNames.map(_ -> Array.fill(admConfig.uuidRemapperShards)(0L)).toMap
  val dedupShardCounts: Map[HostName, Array[Long]] = (hostNameForAllHosts :: hostNames).map(_ -> Array.fill(admConfig.uuidRemapperShards)(0L)).toMap

  val erMap: Map[HostName, Flow[(String,CurrentCdm), Either[ADM, EdgeAdm2Adm], NotUsed]] = ingestConfig.hosts.map { host: IngestHost =>
    host.hostName -> EntityResolution(
      admConfig,
      host,
      cdm2cdmMaps(host.hostName),
      cdm2admMaps(host.hostName),
      blockedEdgesMaps(host.hostName),
      uuidRemapperShardCounts(host.hostName),
      Logging.getLogger(system, this),
      seenNodesMaps(host.hostName),
      seenEdgesMaps(host.hostName),
      dedupShardCounts(host.hostName)
    )
  }.toMap

//  val betweenHostDedup: Flow[Either[ADM, EdgeAdm2Adm], Either[ADM, EdgeAdm2Adm], NotUsed] = if (hostNames.size <= 1) {
//    Flow.apply[Either[ADM, EdgeAdm2Adm]]
//  } else {
//    DeduplicateNodesAndEdges.apply(
//      admConfig.uuidRemapperShards,
//      seenNodesMaps(hostNameForAllHosts),
//      seenEdgesMaps(hostNameForAllHosts),
//      dedupShardCounts(hostNameForAllHosts)
//    )
//  }



  val ppmManagerActors: Map[HostName, ActorRef] = ingestConfig.hosts.map { host: IngestHost =>
    val props = Props(classOf[PpmManager], host.hostName, host.simpleTa1Name, host.isWindows, graph).withDispatcher("adapt.ppm.manager-dispatcher")
    val ref = system.actorOf(props, s"ppm-actor-${host.hostName}")
    host.hostName -> ref
  }.toMap + (hostNameForAllHosts -> system.actorOf(Props(classOf[PpmManager], hostNameForAllHosts, "<no-name>", false, graph), s"ppm-actor-$hostNameForAllHosts"))
  // TODO nichole:  what instrumentation source should I give to the `hostNameForAllHosts` PpmManager? This smells bad...


  val sqidHostPrefix = quineConfig.thishost.replace(".", "-")

  val sqidFile = Some(StandingQueryId(sqidHostPrefix + "_standing-fetch_ESOFile-accumulator"))
  val standingFetchFileActor = system.actorOf(
    Props(
      classOf[StandingFetchActor[ESOFileInstance]],
      implicitly[Queryable[ESOFileInstance]],
      StandingFetches.onESOFileMatch _
    ), sqidFile.get.name
  )

  val sqidSrcSnk = Some(StandingQueryId(sqidHostPrefix + "_standing-fetch_ESOSrcSnk-accumulator"))
  val standingFetchSrcSnkActor = system.actorOf(
    Props(
      classOf[StandingFetchActor[ESOSrcSnkInstance]],
      implicitly[Queryable[ESOSrcSnkInstance]],
      StandingFetches.onESOSrcSinkMatch _
    ), sqidSrcSnk.get.name
  )

  val sqidNetwork = Some(StandingQueryId(sqidHostPrefix + "_standing-fetch_ESONetwork-accumulator"))
  val standingFetchNetworkActor = system.actorOf(
    Props(
      classOf[StandingFetchActor[ESONetworkInstance]],
      implicitly[Queryable[ESONetworkInstance]],
      StandingFetches.onESONetworkMatch _
    ), sqidNetwork.get.name
  )

  val sqidParentProcess = Some(StandingQueryId(sqidHostPrefix + "_standing-fetch_ProcessParentage"))
  val standingFetchProcessParentageActor = system.actorOf(
    Props(
      classOf[StandingFetchActor[ChildProcess]],
      implicitly[Queryable[ChildProcess]],
      StandingFetches.onESOProcessMatch _
    ), sqidParentProcess.get.name
  )

  graph.currentGraph.standingQueryActors = graph.currentGraph.standingQueryActors +
    (sqidFile.get -> standingFetchFileActor) +
    (sqidSrcSnk.get -> standingFetchSrcSnkActor) +
    (sqidNetwork.get -> standingFetchNetworkActor) +
    (sqidParentProcess.get -> standingFetchProcessParentageActor)


  val parallelism = quineConfig.quineactorparallelism
  val quineRouter = system.actorOf(Props(classOf[QuineRouter], parallelism, graph))

  AlarmReporter  // instantiate AlarmReporter (LazyInit) and corresponding actor

  val statusActor = system.actorOf(Props[StatusActor], name = "statusActor")
//  val logFile = config.getString("adapt.logfile")
//  val scheduledLogging = system.scheduler.schedule(10.seconds, 10.seconds, statusActor, LogToDisk(logFile))
//  system.registerOnTermination(scheduledLogging.cancel())

  val streamErrorStrategy: Supervision.Decider = { e: Throwable =>
    e.printStackTrace()
    if (runtimeConfig.quitonerror) Runtime.getRuntime.halt(1)
    Supervision.Resume
  }
  implicit val materializer = ActorMaterializer(ActorMaterializerSettings(system).withSupervisionStrategy(streamErrorStrategy))


  def startWebServer(dbActor: ActorRef): Http.ServerBinding = {
    println(s"Starting the web server at: http://${runtimeConfig.webinterface}:${runtimeConfig.port}")
    val route = Routes.mainRoute(dbActor, statusActor, ppmManagerActors)
    val httpServer = Http().bindAndHandle(route, runtimeConfig.webinterface, runtimeConfig.port)
    Await.result(httpServer, 10 seconds)
  }

  startWebServer(quineRouter)
  statusActor ! InitMsg


  val cdmSources: Map[HostName, (IngestHost, Source[(Namespace,CDM20), NotUsed])] = ingestConfig.hosts.map { host: IngestHost =>
    host.hostName -> (host, host.toCdmSource(ErrorHandler.print))
  }.toMap


  println("Running Quine ingest.")
  RunnableGraph.fromGraph(GraphDSL.create() { implicit b =>
    import GraphDSL.Implicits._
    val hostSources = cdmSources.values.toSeq
    val debug = new StreamDebugger("stream-buffers|", 30 seconds, 10 seconds)
    implicit val mapAsyncUnorderedTimeout = Timeout(0.58 seconds) // NOTE: A good choice here depends on the choice in QuineDBActor of how many retries and how long of a timeout in that use of `retryOnFailure`
    implicit val mapAsyncUnorderedEc = system.dispatchers.lookup("quine.actor.node-dispatcher")
    for (((host, source), i) <- hostSources.zipWithIndex) {
      source
        .via(printCounter(host.hostName, statusActor))
        .via(debug.debugBuffer(s"[${host.hostName}]  0.) before ER"))
        .via(erMap(host.hostName))
        .via(debug.debugBuffer(s"[${host.hostName}]  1.) after ER / before DB"))
        .via(printCounter(host.hostName+" ADM", statusActor))
        .mapAsyncUnordered(parallelism)(adm =>      // TODO: This is too much parallelism for multiple host sources!!!!!!!!!!!!!!!!!!!!!!!!
          retryOnFailure(3)(quineRouter ? adm)
            .recover{ case ignore => () } // Silence unacknowledged futures after multiple deliveries
        ).recover{ case x => println(s"\n\nFAILING AT END OF STREAM.\n\n"); x.printStackTrace() }
        .runWith(Sink.ignore)
    }
    ClosedShape
  }).run()




  Runtime.getRuntime.addShutdownHook(new Thread(new Runnable() {
    override def run(): Unit = if  (!AdaptConfig.skipshutdown) {
      implicit val timeout = Timeout(48 hours)

      println(s"Stopping ammonite...")
      replServer.stopImmediately()

      implicit val executionContext = system.dispatcher

      val saveF = if (ppmConfig.shouldsaveppmtrees) {
        println(s"Saving PPM trees to disk...")
        ppmManagerActors.values.toList.foldLeft(Future.successful(Ack))((a, b) => a.flatMap(_ => (b ? SaveTrees(true)).mapTo[Ack.type]))
      } else {
        Future.successful( Ack )
      }

      val shutdownF = saveF.flatMap { _ =>
        println("Shutting down the actor system")
        system.terminate()
      }.flatMap(_ => Future { mapProxy.closeSync() })

      Await.result(shutdownF, timeout.duration)
    }
  }))


  def wrongRunFlow(): Unit = {
    println(
      raw"""
Unknown runflow argument. Quitting. (Did you mean quine?)

                \
                 \

                        _.-;:q=._
                      .' j=""^k;:\.
                     ; .F       ";`Y
                    ,;.J_        ;'j
                  ,-;"^7F       : .F           _________________
                 ,-'-_<.        ;gj. _.,---""''               .'
                ;  _,._`\.     : `T"5,                       ;
                : `?8w7 `J  ,-'" -^q. `                     ;
                 \;._ _,=' ;   n58L Y.                     .'
                   F;";  .' k_ `^'  j'                     ;
                   J;:: ;     "y:-='                      ;
                    L;;==      |:;   jT\                  ;
                    L;:;J      J:L  7:;'       _         ;
                    I;|:.L     |:k J:.' ,  '       .     ;
                     ;J:.|     ;.I F.:      .           :
                   ;J;:L::     |.| |.J  , '   `    ;    ;
                 .' J:`J.`.    :.J |. L .    ;         ;
                ;    L :k:`._ ,',j J; |  ` ,        ; ;
              .'     I :`=.:."_".'  L J             `.'
            .'       |.:  `"-=-'    |.J              ;
        _.-'         `: :           ;:;           _ ;
    _.-'"             J: :         /.;'       ;    ;
  ='_                  k;.\.    _.;:Y'     ,     .'
     `"---..__          `Y;."-=';:='     ,      .'
              `""--..__   `"==="'    -        .'
                       ``""---...__    itz .-'
                                   ``""---'

"""
    )
    Runtime.getRuntime.halt(1)
  }
}

