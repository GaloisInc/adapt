adapt {
  runflow = "ui" // One of: `ui`, `db`, `csv`, `anomaly`, `accept`
  ingest {

    // Old style for providing data: just a list of the files to ingest
    loadfiles = [] //"/Users/ryan/Desktop/ta1-cadets-pandex-cdm17.bin"] //ta1-trace-cdm17.bin" // ta1-clearscope-cdm17.bin" // cdm17_0407_1607.bin" //  ta1-clearscope-cdm17.bin"  //ta1-cadets-cdm17-3.bin" //]

    // New style for providing data: the keys are provider names, the values are files for that provider
    data {
      "" = ${adapt.ingest.loadfiles}
    }

    startatoffset = 0
    loadlimit = 0    // 0 == no limit
    quitafteringest = no
    logduplicates = no
    produceadm = true
    producecdm = false
  }
  runtime {
    port = 8080
    apitimeout = 301
    dbkeyspace = "neo4j"    // "neo4j" or "titan" is the default value if keyspace is never set
    neo4jkeyspace = ${adapt.runtime.dbkeyspace}
    neo4jfile = ${adapt.runtime.neo4jkeyspace}.db  // "neo4j.db"
    titankeyspace = ${adapt.runtime.dbkeyspace}   // "titan" is the default value if keyspace is never set
    titanthriftframesize = 200  // Default is 15: which definitely fails with normal queries. (we've observed at least 130mb in one frame)
    expansionqueryfreq = 60
    iforestpath = "/home/darpa/iforest.exe"  //  "/Users/ryan/Code/adapt/AdaptJVM/src/main/resources/bin/iforest.exe"  //
    iforestparallelism = 4
    shouldnoramlizeanomalyscores = false
    systemname = "Engagement3"
    quitonerror = no
  }
  env {
    ta1 = "file"  // Either "file" or one of: cadets clearscope faros fivedirections marple theia trace
    scenario = "not used" // "pandex"
    ta1kafkatopic = ta1-${adapt.env.ta1}-e3${adapt.env.farostopicsuffix}  // ta1-${adapt.env.ta1}-${adapt.env.scenario}-cdm17
    theiaresponsetopic = ta1-theia-e3-qr  // TODO: NEED TO CONFIRM WHICH TOPIC TO USE!!!!!!!!!!!!!
    farostopicsuffix = "" // one of: "-psa" "-psb" "-dift" or empty string so that no suffix is used with other TA1s
    kafkabootstrap = "128.55.12.59:9094"  //"ta3-starc-adapt-1-tcip.tc.bbn.com:9092"  //"localhost:9092"
    truststorepath = "/var/private/ssl/kafka.client.truststore.jks"
    trustpass = "TransparentComputing"
    keystorepath = "/var/private/ssl/kafka.client.keystore.jks"
    keypass = "TransparentComputing"
    sslkey = "TransparentComputing"
//    kafkasslenabled = yes
    cdmavroschemafilepath = "/home/darpa/TCCDMDatum18.avsc"
    autooffset = "none"
  }

  // NOTE: these settings are only used if `adapt.ingest.produceadm` is `yes`
  adm {
    parallelism = 10000           // How many futures of resolved ADMs to similtaneously await
    timeoutSeconds = 21474830     // How long before the futures of resolved ADMs should timeout
    maxeventsmerged = 100         // Maximum number of CDM events that can be merged into a single ADM event
    eventexpirysecs = 10          // Expiry time (in seconds, observed tip-of-the-stream time) for event resolution
    maxtimejumpsecs = 100         // Maximum time hop (in seconds) in observed tip-of-the-stream time (does not apply to TimeMarkers)
  }
}

akka {
  loglevel = INFO
  kafka {
    producer {
      close-timeout = 60s
      kafka-clients = ${akka.kafka.consumer.kafka-clients}  //{
//        bootstrap.servers = ${adapt.env.kafkabootstrap}
//
//        security.protocol=SSL
//        ssl.truststore.location=${adapt.env.truststorepath}
//        ssl.truststore.password=${adapt.env.trustpass}
//        ssl.keystore.location=${adapt.env.keystorepath}
//        ssl.keystore.password=${adapt.env.keypass}
//        ssl.key.password=${adapt.env.sslkey}
//      }
    }
    consumer {
      kafka-clients {
        bootstrap.servers = ${adapt.env.kafkabootstrap}
        group.id = ADAPT-${adapt.runtime.systemname}-${adapt.env.ta1}  //-${adapt.env.scenario}

        security.protocol=SSL
        ssl.truststore.location=${adapt.env.truststorepath}
        ssl.truststore.password=${adapt.env.trustpass}
        ssl.keystore.location=${adapt.env.keystorepath}
        ssl.keystore.password=${adapt.env.keypass}
        ssl.key.password=${adapt.env.sslkey}
      }
    }
  }
//  actor.default-dispatcher.throughput = 100000
  http.server {
    interface = "0.0.0.0"
    port = ${adapt.runtime.port}
    request-timeout = ${adapt.runtime.apitimeout} seconds
    idle-timeout = ${akka.http.server.request-timeout}
  }

  log-dead-letters-during-shutdown = no

//  actor.warn-about-java-serializer-usage = no


}


// See mailbox sizes
//akka.actor.default-mailbox {
//  mailbox-type = com.galois.adapt.LoggingMailboxType
//  size-limit = 1000
//}
